### 文献综述：数据精炼与对话流程生成在大规模语言模型中的应用

#### 一、数据精炼对大规模语言模型预训练的影响

1. **背景**
   - 大规模语言模型（LLMs）研究取得显著进展，但如何有效提取高质量子集以提升模型性能仍是挑战。
   - 基于较大模型的困惑度进行剪枝可以生成高质量数据，本研究探讨较小模型是否同样适用。

2. **主要发现**
   - **基于困惑度的预训练数据剪枝**：
     - 不同数据组成情况下，基于困惑度的剪枝显著提升下游任务表现。
     - 使用1.25亿参数模型计算的困惑度剪枝预训练数据，可使30亿参数模型的平均准确率提高1.35%，并减少1.36倍的预训练步骤。

   - **数据精炼技术的应用**：
     - Bane等人（2022年）和Raffel等人（2020年）提出使用符号规则筛选高质量样本。
     - Wenzek等人（2020年）采用简单分类器识别高质量样本。
     - Xie等人（2023b）通过基于特征相似性计算重要性得分重采样高质量文本。
     - Tirumala等人（2023）利用预训练语言模型嵌入进行数据去重。
     - Xie等人（2023a）根据小代理模型的学习能力重新加权领域比例。
     - Marion等人（2023）研究了基于多个神经启发式方法的数据精炼，发现困惑度是最佳精炼指标。

   - **数据集组成的影响**：
     - PILE数据集（15.61%来自CommonCrawl）与自定义网络抓取数据集（87.7%来自CommonCrawl）对比。
     - 剪枝技术在不同数据集组成中表现差异大，最佳技术可能在另一种数据集中表现不佳。

   - **模型参数的影响**：
     - 使用1B和3B参数模型。
     - 在Pile和WDD数据集上，3B参数模型的平均性能普遍高于1B参数模型。

3. **结论**
   - 改进预训练数据质量可在降低成本的同时提升模型性能。
   - 基于困惑度的数据精炼方法不仅减少数据量，还显著提升模型下游任务表现。
   - 数据集领域组成对数据精炼效果有重大影响，需评估多种数据集构成。

#### 二、对话流程生成在大规模语言模型中的应用

1. **背景**
   - 对话系统日益普及，现有数据增强方法主要集中在语言和话题多样性上，忽视了任务逻辑多样性。
   - 面向任务的对话数据集缺乏流程标注和自动化生成机制。

2. **主要发现**
   - 提出新数据增强方法，通过大型语言模型生成决策树结构任务计划，生成多样化对话轨迹（对话流）。
   - 创建包含15个领域3,886个对话流的面向任务对话数据集。
   - 微调模型在下一步动作预测任务中优于GPT-4等基线模型。

3. **结论**
   - 新数据增强方法成功生成符合任务逻辑的多样化对话，提升小型语言模型在特定任务中的表现。
   - 计划公开代码和数据供学术界研究和应用。
   - 未来研究可进一步优化对话流程生成机制以适应复杂任务场景和用户需求。