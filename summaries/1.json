{
    "title": "1.pdf",
    "summary": "### 文献综述：数据精炼对大规模语言模型预训练的影响\n\n#### 背景\n近年来，大规模语言模型（LLMs）的研究取得了显著进展。然而，如何有效地从大规模文本数据集中提取高质量的子集以提升模型性能仍然是一个关键挑战。已有研究表明，基于较大模型的困惑度进行剪枝可以生成高质量数据。本研究进一步探讨了较小模型是否也能用于基于困惑度的剪枝，并分析数据域组成对剪枝的影响。\n\n#### 主要发现\n1. **基于困惑度的预训练数据剪枝**：\n   - 不同数据组成情况下，基于困惑度的预训练数据剪枝显著提升了下游任务的表现。\n   - 使用1.25亿参数模型计算的困惑度来剪枝预训练数据，可以使30亿参数模型的平均准确率提高最多1.35%，同时将预训练步骤减少多达1.36倍以达到相同的基线性能。\n\n2. **数据精炼技术的应用**：\n   - Bane等人（2022年）和Raffel等人（2020年）提出使用符号规则筛选高质量样本。\n   - Wenzek等人（2020年）采用简单的分类器来识别高质量样本。\n   - Xie等人（2023b）通过基于特征相似性计算重要性得分来重采样高质量文本。\n   - Tirumala等人（2023）利用预训练的语言模型嵌入进行数据去重。\n   - Xie等人（2023a）根据一个小的代理模型确定的学习能力重新加权领域比例。\n   - Marion等人（2023）研究了基于多个神经启发式方法的数据精炼，发现样本在参考语言模型下的困惑度是最佳的精炼指标。\n\n3. **数据集组成的影响**：\n   - 研究探讨了两种不同领域组成的预训练数据集：一个是包含多种多样精选领域的PILE数据集（其中只有15.61%的数据来自CommonCrawl），另一个是主要由CommonCrawl数据构成的自定义网络抓取数据集（其中87.7%的数据来自CommonCrawl）。\n   - 发现成功的剪枝技术对不同的数据集组成有很大差异，甚至最佳剪枝技术在一种数据集组成中可能在另一种数据集中表现不佳。\n\n4. **模型参数的影响**：\n   - 使用了两种不同大小的模型参数：1B（十亿）参数和3B（十亿）参数。\n   - 在Pile数据集上，1B参数模型的平均性能为：26.32（世界知识），48.13（常识推理），52.07（语言理解），8.56（符号问题求解），29.94（阅读理解），33.00（综合）；3B参数模型的平均性能为：32.17（世界知识），49.88（常识推理），59.23（语言理解），9.93（符号问题求解），33.06（阅读理解），36.86（综合）。\n   - 在WDD数据集上，1B参数模型的平均性能为：29.8（世界知识），49.68（常识推理），55.97（语言理解），8.59（符号问题求解），32.02（阅读理解），35.21（综合）；3B参数模型的平均性能为：36.5（世界知识），51.75（常识推理），64.15（语言理解），9.4（符号问题求解），34.17（阅读理解），39.19（综合）。\n\n#### 结论\n通过改进预训练数据的质量，可以在减少训练成本的同时提升大型语言模型的性能。基于困惑度的数据精炼方法不仅在减少预训练数据量方面表现出色，还能显著提升模型在下游任务中的表现。此外，数据集的领域组成对数据精炼的效果有很大影响，因此在进行数据精炼研究时需要评估多种不同的数据集构成。"
}